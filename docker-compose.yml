include:
  - redis/docker-compose.yml
  - kafka/docker-compose.yml
  - apps/Market_Reader/docker-compose.yml
  - minio/minio-compose.yaml
  - milvus/docker-compose.yml
  - neo4j/docker-compose.yml
  - telemetry/docker-compose.yml
  - invokeai/docker-compose.yml

services:
  postgres:
    image: postgres:latest
    env_file:
      - .env
    shm_size: 2gb 
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASS}
      - POSTGRES_DB=${DEF_DB_NAME}
      - PGDATA=/data/postgres
    # /mnt/bulkStorage is the 4TB hard disk mount
    volumes:
      - ${PG_STORAGE}:/data/postgres
      - ${SQL_FILE_DIR}:/home
    restart: unless-stopped
    networks:
      - homeserver
    profiles:
      - llm
    ports:
      - "5432:5432"
    container_name: postgres_container

  pgadmin:
    image: dpage/pgadmin4:8.0
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_PW}
    restart: unless-stopped
    user: root
    volumes:
      - ${PGADMIN_STORAGE}:/var/lib/pgadmin
    ports:
      - "${PGADMIN_PORT}:80"
    networks:
     - homeserver
    profiles:
      - llm
    depends_on:
     - postgres
    container_name: pgadmin
    
  ollama:
    image: ollama/ollama
    restart: unless-stopped
    user: root
    volumes:
        - ./ollama:/root/.ollama
    ports:
        - "11434:11434"
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    networks:
     - homeserver
    profiles:
      - llm
    container_name: ollama
  
  # open-webui:
  #   image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
  #   container_name: open-webui
  #   volumes:
  #     - ./ollama/open-webui-data:/app/backend/data
  #   depends_on:
  #     - ollama
  #   environment:
  #     - 'OLLAMA_BASE_URL=http://ollama:11434'
  #     - 'WEBUI_SECRET_KEY='
  #     - 'WEBUI_URL=https://${MY_DNS_NAME}/llm/'
  #     - 'WEBUI_SESSION_COOKIE_SECURE=false'
  #     - 'WEBUI_AUTH_COOKIE_SECURE=false'
  #     - 'ENABLE_WEBSOCKET_SUPPORT=true'
  #     - 'USE_OLLAMA_DOCKER=true'
  #     - 'CORS_ALLOW_ORIGIN=*'
  #   tty: true
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ["0"]
  #             capabilities: [gpu]
  #   networks:
  #    - homeserver
  #   ports:
  #     - 3001:8080
  #   profiles:
  #     - llm
  #   restart: unless-stopped

  proxy:
    build:
      context: ./proxy/
      dockerfile: Dockerfile
      args:
        - SRC_IMG=nginx
        - SRC_TAG=latest
        - PROXY_USER=${PROXY_USER}
        - PROXY_PASSWORD=${PROXY_PASSWORD}
        - no_cache
    environment:
      - PROXY_USER=${PROXY_USER}
      - PROXY_PASSWORD=${PROXY_PASSWORD}
    volumes:
      - ./proxy/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./proxy/${MY_DNS_NAME}.crt:/etc/ssl/certs/${MY_DNS_NAME}.crt
      - ./proxy/${MY_DNS_NAME}.key:/etc/ssl/certs/${MY_DNS_NAME}.key
      - ./proxy/log:/var/log
    ports:
      - "443:443"
      - "80:80"
    restart: no #unless-stopped
    stop_grace_period: 30s
    security_opt:
      - seccomp:unconfined
    networks:
     - homeserver
    profiles:
      - llm
    depends_on:
      - pgadmin
      - telemetry
      - milvusui
      # - open-webui
      - neo4j
      - minio
    container_name: proxy_service

networks:
  homeserver:
    name: homeserver
    labels:
      com.example.description: "home docker network"